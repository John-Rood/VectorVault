{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/drive/1ZnwdlCWEqxufpS-eES47vIYOwZ-6sxco\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install VectorVault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install vector-vault "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# Get Your API Key Here:\n",
    "\n",
    "### >>> [app.vectorvault.io](https://app.vectorvault.io/&aff=stream_any_website_tutorial) <<<\n",
    "*Click the link, enter your email, and an API key will be emailed to you instantly. (You will need this key to access the Vault)*\n",
    "\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Connect to VectorVault\n",
    "Here, we create a Vault instance and set our OpenAI API key as an environment varible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorvault import Vault\n",
    "\n",
    "vault = Vault(user='YOUR_EMAIL', \n",
    "              api_key='YOUR_VECTOR_VAULT_API_KEY', \n",
    "              openai_key='YOUR_OPENAI_API_KEY', \n",
    "              vault='webdump',\n",
    "              verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Download Website and Summarize\n",
    "Use the defualt url already provided to learn about NASA's Mars mission or enter a another url.\n",
    "\n",
    "Then we use the `get_chat()` function with `summary=True` to get a summary of the website. Summary has no limit and can be used to summarize anything, no matter the size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorvault import download_url\n",
    "\n",
    "text_data = download_url(\"https://mars.nasa.gov/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream a summary of the website with the built-in function `print_stream()`\n",
    "summary = vault.print_stream(vault.get_chat_stream(text_data, summary=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "# Save Website Data to Vault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = summary + '\\n' + text_data\n",
    "\n",
    "# Process the data with add()\n",
    "vault.add(text_data)\n",
    "\n",
    "# Get embeddings \n",
    "vault.get_vectors()\n",
    "\n",
    "# Save to Vault\n",
    "vault.save()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "# Ask Your Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = input(\"What's your next question?: \")\n",
    "print(\"Question:\", f\"\\n{user_input}\")\n",
    "\n",
    "# Get response from Language model\n",
    "answer = vault.print_stream(vault.get_chat_stream(user_input, get_context=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## See where the answer is coming from with `return_context=True`\n",
    "In this response, we add conversation history to to the \"get_chat_stream()\" function. We also print the source context that the llm uses for the response. (Since the sources are returned along with the response, we need to choose and fomat the sources return with metatag parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = input(\"What's your next question?: \")\n",
    "print(\"Question:\", f\"\\n{user_input}\")\n",
    "\n",
    "history = user_input + answer\n",
    "\n",
    "# metatag is always a list. 'item_id' will pull the item_id metatag from the metadata. metatag_prefixes/suffixes adds text in the print stream to allow you to format the yielded return\n",
    "answer = vault.print_stream(vault.get_chat_stream(user_input, history=history, get_context=True, return_context=True, metatag=['item_id'], metatag_prefixes=['\\n\\nItem: '], metatag_suffixes=['\\n']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input2 = input(\"What's your next question?: \")\n",
    "print(\"Question:\", f\"\\n{user_input2}\")\n",
    "\n",
    "history = history + user_input + answer\n",
    "\n",
    "# Get response from Language model\n",
    "answer = vault.print_stream(vault.get_chat_stream(user_input2, get_context=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to delete an api key and/or get a new one:\n",
    "\n",
    "# import vectorvault\n",
    "\n",
    "# response = vectorvault.delete_key('YOUR_EMAIL', 'YOUR_VECTOR_VAULT_API_KEY')\n",
    "# print(response)\n",
    "# response = vectorvault.get_new_key('YOUR_EMAIL', 'YOUR_PASSWORD')\n",
    "# print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
