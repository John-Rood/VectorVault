{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/drive/1NsRNRf4SzQejjy8d04LM_AQufaqezFSg\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3zY7Gq1kAkaG"
      },
      "source": [
        "# Install VectorVault"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1q6BVn5AkaI",
        "outputId": "eb1a4c61-e284-41f6-ff90-0cc816820fe5"
      },
      "outputs": [],
      "source": [
        "!pip install vector-vault "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uqifMRF5AkaJ"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "## Get API key to access the Vault Cloud\n",
        "\n",
        "Enter your name, email, and make a password below to get an API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYyA1x9TAkaJ"
      },
      "outputs": [],
      "source": [
        "from vectorvault import register\n",
        "\n",
        "register(first_name='John', last_name='Smith', email='john@smith.com', password='make_a_password')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vMldOWzLAkaK"
      },
      "source": [
        "<br>\n",
        "\n",
        "# Connect to VectorVault\n",
        "In the following code, we import the main Vault class to connect to a vault as well as set our OpenAI API key as an environment varible. We will need that set to process the vectors with `get_vectors` and use the `get_chat()` function later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A06u0ztl4ZDG"
      },
      "outputs": [],
      "source": [
        "%env OPENAI_API_KEY = YOUR_OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDQAu4lKAkaK",
        "outputId": "6b3f60e3-9282-40f6-9ea6-d6e8cfc130f0"
      },
      "outputs": [],
      "source": [
        "from vectorvault import Vault, download_url\n",
        "\n",
        "vault = Vault(user='john@smith.com', api_key='YOUR_VECTOR_VAULT_API_KEY', vault='philosophy', verbose=True)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HBtHCPqFAkaJ"
      },
      "source": [
        "<br>\n",
        "\n",
        "# Download the Philosophy Books \n",
        "1. Download the book texts from the handpicked, refinded data repo of no-copywrite philosophy texts\n",
        "2. Get vectors \n",
        "3. Add to Vault\n",
        "\n",
        "This is a large amount of text and will take roughly 9min to get the vectors and then save them to the cloud. After this is done, referencing the all of them at once will take less than a second.\n",
        "\n",
        "*A Free account will not have the resources to fully finish this. You can stop after the first couple books, or get a [Personal account](https://buy.stripe.com/7sI03AgMldS5b7y7st)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQHHu4uFsZej",
        "outputId": "e7f9ba5b-7336-4e0c-a578-05b1c6ea5341"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import requests \n",
        "\n",
        "vault.delete()\n",
        "\n",
        "# Get the books from the repo\n",
        "response = requests.get(\"https://api.github.com/repos/John-Rood/Philosophy/contents/books\")\n",
        "files = response.json()\n",
        "\n",
        "# Make a loop to download each book since there are 37\n",
        "for file in files:\n",
        "  if file[\"name\"].endswith(\".txt\"):\n",
        "\n",
        "    # Download the book text\n",
        "    file_url = file[\"download_url\"]\n",
        "    text = download_url(file_url)\n",
        "    print(f\"Processing {file_url}\")\n",
        "\n",
        "    # Extract metadata\n",
        "    title = re.search(r\"Title:\\s*(.+)\", text)\n",
        "    author = re.search(r\"Author:\\s*(.+)\", text)\n",
        "\n",
        "    # Handle formatting issues\n",
        "    title = title.group(1).strip() if title else \"Unknown Title\"\n",
        "    author = author.group(1).strip() if author else \"Unknown Author\"\n",
        "\n",
        "    meta = {\n",
        "              \"title\": title,\n",
        "              \"author\": author,\n",
        "            }\n",
        "\n",
        "    # Add for processing\n",
        "    vault.add(text, meta)\n",
        "\n",
        "    # Get vectors for all data added\n",
        "    vault.get_vectors()\n",
        "    \n",
        "    # Save data with vectors to the Vault Cloud\n",
        "    vault.save()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qdRgQeRWAkaK"
      },
      "source": [
        "# Ask Your Question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TK4IO7JBAkaK",
        "outputId": "56346227-0d89-42db-ad78-31dbd78d952e"
      },
      "outputs": [],
      "source": [
        "from vectorvault import wrap\n",
        "\n",
        "user_input = input(\"What's your next question?: \")\n",
        "\n",
        "# Get response from Language model\n",
        "answer = vault.get_chat(user_input, get_context=True)\n",
        "\n",
        "print(\"Question:\", f\"\\n{wrap(user_input)}\", \"\\n\\nAnswer:\", f\"\\n{wrap(answer)}\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "t-1Ve964AkaL"
      },
      "source": [
        "<br>\n",
        "\n",
        "## See where the answer is coming from with `return_context=True`\n",
        "In this response, we add conversation history to to the \"get_chat()\" function. We also print the source context that the llm uses for the response. (Since the sources are returned along with the response, it comes in the form of a dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4Ex4OXbAkaL",
        "outputId": "a235d30e-063a-47d5-f64b-b5d90bd0d01c"
      },
      "outputs": [],
      "source": [
        "user_input2 = input(\"What's your next question?: \")\n",
        "\n",
        "history = user_input + answer\n",
        "\n",
        "# Get response from Language model\n",
        "vault_response = vault.get_chat(user_input2, history=history, get_context=True, return_context=True)\n",
        "\n",
        "# Since 'return_context=True', the response is returned in a dictionary\n",
        "answer = vault_response['response']\n",
        "print(\"Question:\", f\"\\n{wrap(user_input2)}\", \"\\n\\nAnswer:\", f\"\\n{wrap(answer)}\")\n",
        "\n",
        "# show the context used to generate the answer\n",
        "for item in vault_response['context']:\n",
        "    print(\"\\n\\n\", f\"Title: {item['metadata']['title']}\")\n",
        "    print(f\"Author: {item['metadata']['author']}\",\"\\n\\n\")\n",
        "    print(wrap(item['data']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcHqwmerAkaL",
        "outputId": "30083f68-2cc6-4ce4-ec0d-1b47525b546e"
      },
      "outputs": [],
      "source": [
        "user_input3 = input(\"What's your next question?: \")\n",
        "\n",
        "history = history + user_input2 + answer\n",
        "\n",
        "# Get response from Language model\n",
        "response = vault.get_chat(user_input3, history=history, get_context=True)\n",
        "\n",
        "print(\"Question:\", f\"\\n{wrap(user_input3)}\", \"\\n\\nAnswer:\", f\"\\n{wrap(response)}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
